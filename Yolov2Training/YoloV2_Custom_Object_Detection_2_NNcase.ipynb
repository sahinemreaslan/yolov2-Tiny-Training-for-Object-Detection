  {
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4-aAGl5aYF8"
      },
      "source": [
        "181220027 - Şahin Emre ASLAN\n",
        "#Son Gelişmeler:\n",
        "* Oluşturulan veriler yüksek boyutlu olduğu için eğitim(model training) sürecinde sorun yaşandı.\n",
        "* Yaşanan sorun çözüldü,model eğitildi.\n",
        "  #fotoğrafın pixel değerleri modelin girdilerine uygun hale getirildi\n",
        "* Config dosyası içerisinde düzenleme yapılmadan model direk eğitilemez.Lokal olarak upload ederek modeli kendi nesnemi tanıyacak şekilde eğittim.\n",
        "* Modelin donanıma uygun hale getirilmesi gerekiyor.\n",
        "\n",
        "* Model başarıyla donanıma \"NCC\" yazılımıyla donanıma uygun hale getirildi.Modelin başarımının arttırması yönünde çalışmalar yapılmaya çalışılıyor.\n",
        "\n",
        "* Model eğitildi,beklenen başarım görülmedi.Belirlenen ve başarısız olan hiperparametreler:\n",
        "  * epochs = 20, batch-size = 30, learn-rate = 1e-15\n",
        "* Veriseti arttırılacak,Model tekrardan eğitilecektir..(16.05.21)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGcLEWMRaN3q"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sipeed/maix_train --recursive #kullanılan github reposu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QspAoDzaMGkx"
      },
      "outputs": [],
      "source": [
        "%cd /content/maix_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-9Y8gd7MIaZ"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt #kullanılan kütüphanelerin versiyon gereksinimleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5LJcRdaaQbP"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "#githubdan çektiğimiz içinde yüklü olan verisetilerini siliyoruz\n",
        "!rm -r /content/sample_data\n",
        "!rm -r /content/maix_train/datasets/test-TFRecords-export.zip \n",
        "!rm -r /content/maix_train/datasets/test_classifier_datasets.zip \n",
        "!rm -r /content/maix_train/datasets/test_detector_xml_format.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbjrKTQFdBEZ"
      },
      "outputs": [],
      "source": [
        "#kendi verisetimi yüklüyorum\n",
        "  #Transfer Learning = xml_format_TL.zip\n",
        "  #default dataset = xml_format_dataset.zip\n",
        "!gdown https://drive.google.com/uc?id=1kh1ZBc84WdKL6nSQckzpRpC6Js153nGn\n",
        "#shutil.move(\"xml_format2.zip\",\"datasets\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer learning\n",
        "!gdown https://drive.google.com/uc?id=1Ru_sAYgVQzHuPLYdEIzM3aCRTyZ12qAd\n",
        "!gdown https://drive.google.com/uc?id=1Fg2zZK6kP9IYzavS1NAcvJmtK-lUbsn_\n",
        "!rm -r /content/maix_train/train/classifier/__init__.py\n",
        "shutil.move(\"__init__.py\",\"/content/maix_train/train/classifier/__init__.py\")"
      ],
      "metadata": {
        "id": "t47pUZi9wpGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFs5Edg8aRaD"
      },
      "outputs": [],
      "source": [
        "!python3 train.py init #config dosyası oluşturur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-0yjYE5aSrK"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=17QlZfTJq7t4QNXH0GTZcVnTM-tLODpqg #kendi config dosyamı yüklüyor\n",
        "shutil.move(\"config.py\",\"/content/maix_train/instance/config.py\") #taşıma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAv8VptynZfO"
      },
      "outputs": [],
      "source": [
        "#dönüştürücü yazılımı yüklenmesi .h5 to .kmodel\n",
        "!wget -P /content/maix_train/tools/ncc/ncc_v0.1 https://github.com/kendryte/nncase/releases/download/v0.1.0-rc5/ncc-linux-x86_64.tar.xz\n",
        "%cd /content/maix_train/tools/ncc/ncc_v0.1\n",
        "!tar xvf /content/maix_train/tools/ncc/ncc_v0.1/ncc-linux-x86_64.tar.xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b-NV1GUaTmI"
      },
      "outputs": [],
      "source": [
        "%cd /content/maix_train\n",
        "!python3 train.py -t detector -z /content/maix_train/datasets/xml_format_HQ_tf.zip train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OQI6J7mOWKw"
      },
      "source": [
        "#Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDtX3ooHOVrw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Section\n",
        "This is section in OV2640 used camera images.\n",
        "\n"
      ],
      "metadata": {
        "id": "0FabHKaXFvRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import cv2\n",
        "from collections import Iterable\n",
        "\n",
        "from dataset import Dataset_Folder, Dataset_VOC\n",
        "from dataloader import DataLoader\n",
        "from logger import Logger\n",
        "from augmentations import SSDAugmentationTest, DeNormalize\n",
        "from draw import Draw\n",
        "\n",
        "class Net_Test:\n",
        "    def __init__(self, dataset, classes, net_type, saved_state_path, input_shape=(3, 240, 240), anchors = None, temp_dir=None, conf_thresh=0.3, nms_thresh=0.3, opt = {}, log = Logger(), device=\"cuda\"):\n",
        "        '''\n",
        "            @input_layout only support default now, pytorch is chw, tensorflow is hwc\n",
        "        '''\n",
        "        self.classes = classes\n",
        "        self.net_type = net_type\n",
        "        self.log = log\n",
        "        self.anchors = self.val_anchors(anchors)\n",
        "        self.input_shape = input_shape\n",
        "        if not temp_dir:\n",
        "            temp_dir = os.path.join(\"out\", net_type, \"test_result\")\n",
        "        self.temp_dir = temp_dir\n",
        "        if not os.path.exists(self.temp_dir):\n",
        "            os.makedirs(self.temp_dir)\n",
        "        self.root = os.path.abspath(os.path.dirname(__file__))\n",
        "        detectors_path = os.path.join(self.root, \"detectors\")\n",
        "        sys.path.insert(0, detectors_path)\n",
        "        self.detector = __import__(net_type)\n",
        "        try:\n",
        "            self.framework = self.detector.framwork\n",
        "        except Exception:\n",
        "            self.framework = \"torch\"\n",
        "        self.tester = self.detector.Test(\n",
        "                            self.classes, self.anchors,\n",
        "                            (self.input_shape[2], self.input_shape[1]),\n",
        "                            saved_state_path,\n",
        "                            self.log,\n",
        "                            conf_thresh,\n",
        "                            nms_thresh,\n",
        "                            device\n",
        "                        )\n",
        "        self.dataset = dataset\n",
        "        self.curr_idx = 0\n",
        "        self.draw = Draw(self.classes)\n",
        "    \n",
        "    def detect(self, index = -1, get_img_path = False):\n",
        "        if index >= 0:\n",
        "            img = self.dataset[index]\n",
        "            img_raw = self.dataset.pull_image(index, get_img_path=get_img_path)\n",
        "        else:    \n",
        "            if self.curr_idx >= len(self.dataset):\n",
        "                return None\n",
        "            img = self.dataset[self.curr_idx] # img or (img, target)\n",
        "            if isinstance(img, Iterable):\n",
        "                img = img[0]\n",
        "            img_raw = self.dataset.pull_image(self.curr_idx, get_img_path=get_img_path)\n",
        "            self.curr_idx += 1\n",
        "        boxes, probs, inds = self.tester.detect(img)\n",
        "        return img_raw, boxes, probs, inds\n",
        "\n",
        "    def show(self, img, boxes, probs, inds, save_path = None, threshold = -1):\n",
        "        img = self.draw.draw_img(img, boxes, inds, self.classes, probs, threshold)\n",
        "        if save_path:\n",
        "            cv2.imwrite(save_path, img)\n",
        "        \n",
        "\n",
        "    def reset(self):\n",
        "        self.curr_idx = 0\n",
        "\n",
        "    def val_anchors(self, anchors):\n",
        "        '''\n",
        "            convert [w, h, w, h, ...] to [[w, h], [w, h], ...]\n",
        "        '''\n",
        "        if type(anchors[0]) == list or type(anchors[0]) == tuple:\n",
        "            return anchors\n",
        "        final = []\n",
        "        for i in range(0, len(anchors)//2):\n",
        "            final.append([anchors[i * 2], anchors[i * 2 + 1]])\n",
        "        return final\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"mouse\", \"microbit\", \"ruler\", \"cat\", \"peer\", \"ship\", \"apple\", \"car\", \"pan\", \"dog\", \"umbrella\", \"airplane\", \"clock\", \"grape\", \"cup\", \"left\", \"right\", \"front\", \"stop\", \"back\"]\n",
        "    # anchors = [[2.44, 2.25], [5.03, 4.91], [3.5, 3.53], [4.16, 3.94], [2.97, 2.84]]\n",
        "    # param_path = \"out/yolov2_slim/weights/epoch_460.pth\"\n",
        "    # test_dir = \"datasets/cards/cap/left\"\n",
        "\n",
        "\n",
        "    classes = [\"hedef\"]\n",
        "    anchors = [[1.87, 5.32], [1.62, 3.28], [1.75, 3.78], [1.33, 3.66], [1.5, 4.51]]\n",
        "    param_path = \"out/lobster_5classes/yolov2_slim/weights/epoch_15.pth\"\n",
        "    test_dir = \"datasets/lobster_5classes\"\n",
        "    is_val_data = True\n",
        "\n",
        "    input_shape=(3, 224, 224)\n",
        "\n",
        "    log = Logger()\n",
        "\n",
        "    if is_val_data:\n",
        "        dataset = Dataset_VOC(classes, test_dir, sets=[\"val\"], log = log,\n",
        "                            transform = SSDAugmentationTest(size=input_shape[1:][::-1], mean=(0.5, 0.5, 0.5), std=(128/255.0, 128/255.0, 128/255.0))\n",
        "                            )\n",
        "    else:\n",
        "        dataset = Dataset_Folder(test_dir,\n",
        "                    transform = SSDAugmentationTest(size=input_shape[1:][::-1], mean=(0.5, 0.5, 0.5), std=(128/255.0, 128/255.0, 128/255.0)),\n",
        "                    log = log\n",
        "                    )\n",
        "    test = Net_Test(dataset,\n",
        "                classes,\n",
        "                \"yolov2_slim\",\n",
        "                param_path,\n",
        "                input_shape=input_shape,\n",
        "                anchors=anchors,\n",
        "                conf_thresh=0.2,\n",
        "                nms_thresh=0.3,\n",
        "                log = log,\n",
        "                device=\"cpu\"\n",
        "                )\n",
        "    count = 0\n",
        "    while 1:\n",
        "        result = test.detect()\n",
        "        if not result:\n",
        "            break\n",
        "        img, boxes, probs, inds = result\n",
        "        out_jpg = \"out/test.jpg\"\n",
        "        test.show(img, boxes, probs, inds, save_path=out_jpg)\n",
        "        input(f\"[{count}] see {out_jpg}, press any key to continue\")\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "WyPe7YNYGCOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "38e6ad25-69d3-4ca9-8491-e9bf3036127d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-696b4e10a1d4>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    from dataset import /content/maix_train/Dataset_Folder/Dataset_Folder, Dataset_VOC\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkXAqeSe40bd"
      },
      "source": [
        "# Bundan sonraki aşamalarda modelin başarımı(acc) arttırılmaya çalışılacaktır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhSf0IznovY8"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "string = 'epoch20_batc10_learn-5.zip'\n",
        "newZip = zipfile.ZipFile(string, 'w')\n",
        "newZip.write(os.listdir('/content/maix_train/epoch20_batc10_learn-5'), compress_type=zipfile.ZIP_DEFLATED)\n",
        "newZip.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "812JITsUqVct"
      },
      "outputs": [],
      "source": [
        "#modeli google drive a çekme\n",
        "import os\n",
        "COLAB_MODEL ='/content/maix_train/epoch20_batc10_learn-5'\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/model_proje/'\n",
        "shutil.copytree(COLAB_MODEL, DRIVE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpXi0JW03weX"
      },
      "outputs": [],
      "source": [
        "#Modelin Başarımını Ölçme\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "plt.figure()\n",
        "plt.axis(\"off\")\n",
        "foto = cv2.imread(\"/content/maix_train/out/result_root_dir/maixhub_detector_result_2021_10_22__12_06/report.jpg\")\n",
        "plt.imshow(foto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9EfRQPnu1Qh"
      },
      "outputs": [],
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yQ9xABku3Bs"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\n",
        "print(model_path)\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "model = models.convert_model(model)\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pandas.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bddrBIoZu5bB"
      },
      "outputs": [],
      "source": [
        "def img_inference(img_path):\n",
        "  image = read_image_bgr(img_infer)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < THRES_SCORE\n",
        "      {}\n",
        "          break\n",
        "\n",
        "      color = label_color(label)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "\n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      print(caption)\n",
        "      draw_caption(draw, b, caption)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(draw)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsdzBEMGu6lB"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "img_infer = list(uploaded)[0]\n",
        "\n",
        "print('Running inference on: ' + img_infer)\n",
        "img_inference(img_infer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JkXAqeSe40bd"
      ],
      "name": "MaixDuino_Hedef_Tanıma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
